{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import threading\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from objloader_simple import *\n",
    "from collections import deque\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projection_matrix(camera_parameters, homography):\n",
    "    \"\"\"\n",
    "    From the camera calibration matrix and the estimated homography\n",
    "    compute the 3D projection matrix\n",
    "    \"\"\"\n",
    "    homography = homography * (-1)\n",
    "    rot_and_transl = np.dot(np.linalg.inv(camera_parameters), homography)\n",
    "    col_1 = rot_and_transl[:, 0]\n",
    "    col_2 = rot_and_transl[:, 1]\n",
    "    col_3 = rot_and_transl[:, 2]\n",
    "\n",
    "    # Normalize vectors\n",
    "    l = math.sqrt(np.linalg.norm(col_1, 2) * np.linalg.norm(col_2, 2))\n",
    "    rot_1 = col_1 / l\n",
    "    rot_2 = col_2 / l\n",
    "    translation = col_3 / l\n",
    "\n",
    "    # Compute the orthonormal basis\n",
    "    c = rot_1 + rot_2\n",
    "    p = np.cross(rot_1, rot_2)\n",
    "    d = np.cross(c, p)\n",
    "    rot_1 = np.dot(\n",
    "        c / np.linalg.norm(c, 2) + d / np.linalg.norm(d, 2), 1 / math.sqrt(2)\n",
    "    )\n",
    "    rot_2 = np.dot(\n",
    "        c / np.linalg.norm(c, 2) - d / np.linalg.norm(d, 2), 1 / math.sqrt(2)\n",
    "    )\n",
    "    rot_3 = np.cross(rot_1, rot_2)\n",
    "\n",
    "    # Compute the 3D projection matrix from the model to the current frame\n",
    "    projection = np.stack((rot_1, rot_2, rot_3, translation)).T\n",
    "\n",
    "    return np.dot(camera_parameters, projection)\n",
    "\n",
    "\n",
    "def render(frame, obj, projection, referenceImage, scale3d, color=False):\n",
    "    \"\"\"\n",
    "    Render a loaded obj model into the current video frame\n",
    "    \"\"\"\n",
    "    vertices = obj.vertices\n",
    "    scale_matrix = np.eye(3) * scale3d\n",
    "    h, w = referenceImage.shape[0:2]\n",
    "\n",
    "    for face in obj.faces:\n",
    "        face_vertices = face[0]\n",
    "        points = np.array([vertices[vertex - 1] for vertex in face_vertices])\n",
    "        points = np.dot(points, scale_matrix)\n",
    "\n",
    "        # render model in the middle of the reference surface. To do so,\n",
    "        # model points must be displaced\n",
    "        points = np.array([[p[0] + w / 2, p[1] + h / 2, p[2]] for p in points])\n",
    "        dst = cv2.perspectiveTransform(points.reshape(-1, 1, 3), projection)\n",
    "        framePts = np.int32(dst)\n",
    "\n",
    "        cv2.fillConvexPoly(frame, framePts, (137, 27, 211))\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera accessed successfully.\n"
     ]
    }
   ],
   "source": [
    "# ============== Read data ==============\n",
    "\n",
    "# Load 3D model from OBJ file\n",
    "obj = OBJ(\"./models/chair.obj\", swapyz=True)\n",
    "\n",
    "# Scale 3D model\n",
    "scale3d = 8\n",
    "\n",
    "# Matrix of camera parameters\n",
    "camera_parameters = np.array([[800, 0, 320], [0, 800, 240], [0, 0, 1]])\n",
    "\n",
    "# Minimum number of matches\n",
    "MIN_MATCHES = 15\n",
    "\n",
    "# ============== Reference Image ==============\n",
    "# Init video capture (load the source image)\n",
    "cap = cv2.VideoCapture(\"../VideoOperation/mysupervideo.mp4\")\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video capture.\")\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    pass\n",
    "else:\n",
    "    print(\"Camera accessed successfully.\")\n",
    "\n",
    "# Load reference image and convert it to gray scale\n",
    "ret, referenceImage = cap.read()\n",
    "\n",
    "# ================== Recognize ================\n",
    "\n",
    "# Initiate ORB detector\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# create brute force  matcher object\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "# Compute model keypoints and its descriptors\n",
    "referenceImagePts, referenceImageDsc = orb.detectAndCompute(referenceImage, None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============== Source Images ==============\n",
    "while True:\n",
    "    # read the current frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # ============== Recognize =============\n",
    "    # Compute scene keypoints and its descriptors\n",
    "    sourceImagePts, sourceImageDsc = orb.detectAndCompute(frame, None)\n",
    "\n",
    "    # ============== Matching =============\n",
    "\n",
    "    # Match frame descriptors with model descriptors\n",
    "    matches = bf.match(referenceImageDsc, sourceImageDsc)\n",
    "\n",
    "    # Sort them in the order of their distance\n",
    "    matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "    # ============== Homography =============\n",
    "\n",
    "    # Apply the homography transformation if we have enough good matches\n",
    "    if len(matches) > MIN_MATCHES:\n",
    "        # Get the good key points positions\n",
    "        sourcePoints = np.float32(\n",
    "            [referenceImagePts[m.queryIdx].pt for m in matches]\n",
    "        ).reshape(-1, 1, 2)\n",
    "        destinationPoints = np.float32(\n",
    "            [sourceImagePts[m.trainIdx].pt for m in matches]\n",
    "        ).reshape(-1, 1, 2)\n",
    "\n",
    "        # Obtain the homography matrix\n",
    "        homography, _ = cv2.findHomography(\n",
    "            sourcePoints, destinationPoints, cv2.RANSAC, 5.0\n",
    "        )\n",
    "\n",
    "        # Apply the perspective transformation to the source image corners\n",
    "        h, w, = referenceImage.shape[0:2]\n",
    "        corners = np.float32(\n",
    "            [[0, 0], [0, h - 1], [w - 1, h - 1], [w - 1, 0]]\n",
    "        ).reshape(-1, 1, 2)\n",
    "        transformedCorners = cv2.perspectiveTransform(corners, homography)\n",
    "\n",
    "        # Draw a polygon on the second image joining the transformed corners\n",
    "        frame = cv2.polylines(\n",
    "            frame, [np.int32(transformedCorners)], True, 255, 3, cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # ================= Pose Estimation ================\n",
    "\n",
    "        # obtain 3D projection matrix from homography matrix and camera parameters\n",
    "        projection = projection_matrix(camera_parameters, homography)\n",
    "\n",
    "        # project cube or model\n",
    "        frame = render(frame, obj, projection, referenceImage, scale3d, False)\n",
    "\n",
    "        # ===================== Display ====================\n",
    "        \n",
    "        # show result\n",
    "        time.sleep(1/20)\n",
    "        cv2.imshow(\"frame\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "    else:\n",
    "        print(\"Not enough matches are found - %d/%d\" % (len(matches), MIN_MATCHES))\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-8.01102055e+02, -1.40412643e+00,  3.17227877e+02,\n",
       "         6.72532517e+02],\n",
       "       [-5.40938547e-01, -8.00838476e+02,  2.37186515e+02,\n",
       "         4.12922422e+02],\n",
       "       [-3.45904102e-03, -3.51443911e-03,  9.99987842e-01,\n",
       "        -7.97937512e+02]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
